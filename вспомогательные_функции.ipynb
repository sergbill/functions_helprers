{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _target_encoding(xtr, xholdout, xte, to_enc, nfolds, num_iterations, min_samples_leaf):\n",
    "    \n",
    "    '''\n",
    "    кодирует категории целевым признаком \n",
    "    \n",
    "    Параметры:\n",
    "        1) xtr - трейн\n",
    "        2) xholdout - отложенная\n",
    "        3) xte - тест\n",
    "        4) to_enc-колонки, которые кодируются\n",
    "        5) nfolds- число фолдов\n",
    "        6) num_iterations = число итераций кодирования\n",
    "    '''\n",
    "    # списки с кодированиями\n",
    "    encs_tr, encs_holdout, encs_te = [], [], []\n",
    "    # проходим по числу итераций\n",
    "    for _ in tqdm_notebook(range(num_iterations)):\n",
    "        # задаем датафреймы, которые будем заполнять\n",
    "        enc_tr = pd.DataFrame(index = xtr.index, columns = to_enc).fillna(0.0)\n",
    "        enc_holdout = pd.DataFrame(index = xholdout.index, columns = to_enc).fillna(0.0)\n",
    "        enc_te = pd.DataFrame(index = xte.index, columns = to_enc).fillna(0.0)\n",
    "        # запускаем валидацию\n",
    "        for i, (tr_idx, val_idx) in enumerate(KFold(nfolds, random_state = _).split(xtr)):\n",
    "            # получаем датафрейм, на котором будет оцениваться средний таргет\n",
    "            _df_tr = pd.concat([xtr.iloc[tr_idx], ytr.iloc[tr_idx]], 1)\n",
    "            # считаем средний таргет на всем трейн датасете\n",
    "            y_tr_mean = ytr.iloc[tr_idx].mean()\n",
    "            # проходим по колонкам, которые будут кодироваться\n",
    "            for col in to_enc:  \n",
    "                # словарь с мапингом среднего таргета по категорям,\n",
    "                # (ограниченный минимальным размером категории, для которого будет считаться средний таргет)\n",
    "                _ddf =_df_tr.groupby(col)['target'].agg({'mean', 'count'})\n",
    "                d_map = _ddf[_ddf['count']>=min_samples_leaf]['mean'].to_dict()\n",
    "                # применяем кодирование на валидации + шум\n",
    "                enc_tr.loc[xtr.iloc[val_idx].index, col] = xtr.iloc[val_idx][col].map(d_map)\\\n",
    "                                                            + np.random.normal(y_tr_mean/100, y_tr_mean/500, size = len(val_idx))\n",
    "                # применяем кодирование на отложенной, нормируя на число фолдов + шум\n",
    "                enc_holdout.loc[:, col] += (xholdout[col].map(d_map)\\\n",
    "                                            + np.random.normal(y_tr_mean/100, y_tr_mean/500, size = len(xholdout)))\\\n",
    "                                            / nfolds \n",
    "                # применяем кодирование на тесте, нормируя на число фолдов + шум\n",
    "                enc_te.loc[:, col] += (xte[col].map(d_map)\\\n",
    "                                            + np.random.normal(y_tr_mean/100, y_tr_mean/500, size = len(xte)))\\\n",
    "                                            / nfolds \n",
    "        # коллекционируем кодирования\n",
    "        encs_tr.append(enc_tr)\n",
    "        encs_holdout.append(enc_holdout)\n",
    "        encs_te.append(enc_te)\n",
    "        \n",
    "    # усредняем коллекции кодирований\n",
    "    enc_final_tr = sum(encs_tr) / len(encs_tr)  \n",
    "    enc_final_holdout = sum(encs_holdout) / len(encs_holdout)   \n",
    "    enc_final_te = sum(encs_te) / len(encs_te)  \n",
    "    \n",
    "    return (enc_final_tr, enc_final_holdout, enc_final_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _do_stacking(estimators, xtr, xholdout, xte, nfolds, num_iterations):\n",
    "    \n",
    "    '''\n",
    "    кодирует категории целевым признаком \n",
    "    \n",
    "    Параметры:\n",
    "        1) xtr - трейн\n",
    "        2) xholdout - отложенная\n",
    "        3) xte - тест\n",
    "        4) estimators - базовые модели\n",
    "        5) nfolds- число фолдов\n",
    "        6) num_iterations = число итераций кодирования\n",
    "    '''\n",
    "    # списки с метапризнаками\n",
    "    oofs_tr, oofs_holdout, oofs_te = [], [], []\n",
    "    # проходим по числу итераций\n",
    "    for _ in tqdm_notebook(range(num_iterations)):\n",
    "        # задаем датафреймы, которые будем заполнять\n",
    "        oof_tr = pd.DataFrame(index = xtr.index, columns = ['oof_predictions']).fillna(0.0)\n",
    "        oof_holdout = pd.DataFrame(index = xholdout.index, columns = ['oof_predictions']).fillna(0.0)\n",
    "        oof_te = pd.DataFrame(index = xte.index, columns = ['oof_predictions']).fillna(0.0)         \n",
    "        # запускаем валидацию\n",
    "        for i, (tr_idx, val_idx) in enumerate(KFold(nfolds, random_state = _).split(xtr)): \n",
    "            # проходим по моделям\n",
    "            for estimaor in estimators:\n",
    "                # фитим на трейне\n",
    "                estimator.fit(xtr.iloc[tr_idx], ytr.iloc[tr_idx])\n",
    "                # предсказываем валидацию\n",
    "                oof_tr.loc[xtr.iloc[val_idx].index, 'oof_predictions'] = estimator.predict_proba(xtr.iloc[val_idx])[:, 1]\n",
    "                # усредняем предсказания каждого фолда на отложенной и на тесте\n",
    "                oof_holdout.loc[:, 'oof_predictions'] += estimator.predict_proba(xholdout)[:, 1] / nfolds\n",
    "                oof_te.loc[:, 'oof_predictions'] += estimator.predict_proba(xte)[:, 1] / nfolds\n",
    "        # коллекционируем метапризнаки\n",
    "        oofs_tr.append(oof_tr)\n",
    "        oofs_holdout.append(oof_holdout)\n",
    "        oofs_te.append(oof_te)\n",
    "        \n",
    "    # усредняем списки с метапризнаками\n",
    "    oofs_final_tr = sum(oofs_tr) / len(oofs_tr)  \n",
    "    oofs_final_holdout = sum(oofs_holdout) / len(oofs_holdout)   \n",
    "    oofs_final_te = sum(oofs_te) / len(oofs_te)  \n",
    "    \n",
    "    return (oofs_final_tr, oofs_final_holdout, oofs_final_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tune_lgb(xtr, xholdout, ytr, yholdout, metric, eval_metric, paramGrid, cv, early_stopping_rounds, type_task):\n",
    "    '''\n",
    "    Оптимизирует гиперпараметры lightgbm\n",
    "    \n",
    "    Параметры:\n",
    "        1) xtr - признаки на трейне\n",
    "        2) xholdout - признаки на отложенной\n",
    "        3) ytr - таргет на трейне\n",
    "        4) yholdout - таргет на отложенной\n",
    "        5) metric - оптимизируемая метрика качества\n",
    "        6) eval_metric - метрика для ранней остановки\n",
    "        7) paramGrid - сетка перебора\n",
    "        8) cv - схема валидации\n",
    "        9) early_stopping_rounds - ранняя остановка\n",
    "        10) type_task - тип задачи\n",
    "        \n",
    "    Возвращает: лучшую метрику, лучшие параметры\n",
    "    '''\n",
    "    \n",
    "    if type_task == 'classification':\n",
    "        model = lgb.sklearn.LGBMClassifier(random_state =SEED)\n",
    "    else:\n",
    "        model = lgb.sklearn.LGBMRegressor(random_state =SEED)\n",
    "            \n",
    "    if (early_stopping_rounds is not None) and (eval_metric is not None):\n",
    "        fit_params={\"early_stopping_rounds\":early_stopping_rounds, \n",
    "                    \"eval_metric\" : eval_metric, \n",
    "                    \"eval_set\" : [[xholdout, yholdout]]}\n",
    "        gridsearch = GridSearchCV(model, paramGrid, verbose=0,             \n",
    "             cv=cv, scoring = metric)\n",
    "\n",
    "        gridsearch.fit(xtr, ytr, **fit_params)\n",
    "        \n",
    "        return (gridsearch.best_score_, gridsearch.best_params_)\n",
    "    elif (early_stopping_rounds is None) and (eval_metric is None):\n",
    "        gridsearch = GridSearchCV(model, paramGrid, verbose=0,             \n",
    "             cv=cv, scoring = metric)\n",
    "        gridsearch.fit(xtr, ytr)\n",
    "        \n",
    "        return (gridsearch.best_score_, gridsearch.best_params_)\n",
    "    else:\n",
    "        raise ValueError('early stopping и eval metric должны быть None или not None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _select_features(clf, xtr, ytr, cv, metric):\n",
    "    \n",
    "    '''\n",
    "    Отбирает признаки (метрика = roc auc)\n",
    "    \n",
    "    Параметры:\n",
    "        1) clf - модель\n",
    "        2) xtr - признаки\n",
    "        3) ytr - таргет\n",
    "        4) cv - схема валидации\n",
    "        5) early_stopping - кол-во итераций без улучшения метрики для остановки первой стадии отбора\n",
    "        6) min_diff_continue - минимальное кол-во отобранных признаков за итерацию для продолжения второй стадии отбора\n",
    "    \n",
    "    Возвращает:\n",
    "        лучшее значение метрики, лучший набор признаков\n",
    "    '''\n",
    "    \n",
    "    # валидируем каждый признак\n",
    "    scores = []\n",
    "    for i in tqdm_notebook(range(xtr.shape[1])):\n",
    "        scores.append(cross_validate(clf, xtr[:, i].reshape(-1,1),\\\n",
    "                                     ytr, scoring ='roc_auc', cv = cv)['test_score'].mean())\n",
    "    # сортируем индивидуальные скоры в порядке убывания\n",
    "    order = np.argsort(scores)[::-1]\n",
    "    # лучший скор, лучшие признаки, признаки для проверки, счетчик ранней остановки\n",
    "    best_score, best_features, to_drop, = .5, [], []\n",
    "    # по признакам в порядке убывания индивидуальных скоров\n",
    "    for i in tqdm_notebook(order):\n",
    "        # добавляем признак в список лучших\n",
    "        current_features = best_features+[i]\n",
    "        # считаем валидацю\n",
    "        mean_score = cross_validate(clf, xtr[:, current_features],\\\n",
    "                                     ytr, scoring =metric, cv = cv)['test_score'].mean()\n",
    "        # если есть улучшение\n",
    "        if mean_score > best_score:\n",
    "            # обновляем лучший скор\n",
    "            best_score = mean_score\n",
    "            # обновляем лучшие признаки\n",
    "            best_features = current_features            \n",
    "            \n",
    "        # если улчшения нет\n",
    "        else:\n",
    "            # добавляем признак в кандидаты на удаление\n",
    "            to_drop.append(i)\n",
    "            # обновляем счетчик\n",
    "    print('лучшее значение метрики = {}'.format(best_score))\n",
    "    # списки на удаление признаков ДО и ПОСЛЕ отбора\n",
    "    to_drop_before = to_drop\n",
    "    to_drop_after = []\n",
    "    # запускаем бесконечный цикл\n",
    "    while True:\n",
    "        # добавляем последовательно признаки из кандидатов на удаление\n",
    "        for i in tqdm_notebook(to_drop_before):\n",
    "            current_features = best_features+[i]\n",
    "            mean_score = cross_validate(clf, xtr[:, current_features],\\\n",
    "                                     ytr, scoring =metric, cv = cv)['test_score'].mean()\n",
    "            # если есть улучшение скора\n",
    "            if mean_score > best_score:\n",
    "                # обновляем лучший скор\n",
    "                best_score = mean_score\n",
    "                # обновляем лучшие признаки\n",
    "                best_features = current_features            \n",
    "            else:\n",
    "                # добавляем признак в кандидаты на удаление ПОСЛЕ\n",
    "                to_drop_after.append(i)\n",
    "                \n",
    "        # если списки ДО и ПОСЛЕ отличаются меньше, чем на 5 признаков \n",
    "        if len(to_drop_before) == len(to_drop_after):\n",
    "            # останавливаем отбор\n",
    "            break\n",
    "        else:\n",
    "            # ДО --> ПОСЛЕ, ПОСЛЕ - пустой\n",
    "            to_drop_before = to_drop_after\n",
    "            to_drop_after = []\n",
    "        print('лучшее значение метрики = {}'.format(best_score))\n",
    "            \n",
    "    return (best_score, best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _exclude_outliers_iqr(series):\n",
    "    '''\n",
    "    помечает выбросы (найденные с помощью интерквартильного размаха)\n",
    "    '''\n",
    "    q25, q75 = series.quantile([.25, .75])\n",
    "    iqr = q75-q25\n",
    "    return series.between(q25-1.5*iqr, q75+1.5*iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _identify_different_distributions(xtr, xholdout, alpha):\n",
    "    '''\n",
    "    проверят идентичность распределений признаков в трейне и в отложенной частях\n",
    "    (тест колмогорова-смирнова)\n",
    "    \n",
    "    Возвращает: True, если различия есть,иначе - False\n",
    "    '''\n",
    "    \n",
    "    flags = []\n",
    "    for col in sites:\n",
    "        ser1 = xtr[col]\n",
    "        ser2 = xholdout[col]\n",
    "        if stats.ks_2samp(ser1, ser2)[1] < alpha:\n",
    "            flags.append(True)\n",
    "        else:\n",
    "            flags.append(False)        \n",
    "    flags = np.array(flags)    \n",
    "    if flags.sum() > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_holdout_split(X, y, holdout_share, seed, stratify, shuffle):\n",
    "    '''\n",
    "    делит данные на трейн и отложенную части\n",
    "    \n",
    "    парметры:\n",
    "        1) X - признаки\n",
    "        2) y - таргет\n",
    "        3) holdout_share - доля отложенной выборки\n",
    "        4) seed - генератор случайных чисел\n",
    "        5) stratify - стратификация таргета (TRUE, FALSE)\n",
    "        6) shuffle - перемешивание данных (TRUE, FALSE)\n",
    "        \n",
    "    возвращает: признаки трейн, признаки отоженная, таргет трейн, таргет отложенная\n",
    "    '''\n",
    "    if stratify:\n",
    "        if shuffle:\n",
    "            xtr, xholdout, ytr, yholdout = train_test_split(X, y, test_size = holdout_share, stratify = y, random_state = seed)\n",
    "        else:\n",
    "            xtr, xholdout, ytr, yholdout = train_test_split(X, y, test_size = holdout_share, stratify = y)\n",
    "            \n",
    "    else:\n",
    "        if shuffle:\n",
    "            xtr, xholdout, ytr, yholdout = train_test_split(X, y, test_size = holdout_share, random_state = seed)\n",
    "        else:\n",
    "            xtr, xholdout, ytr, yholdout = train_test_split(X, y, test_size = holdout_share)\n",
    "            \n",
    "    return (xtr, xholdout, ytr, yholdout)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_data_report(df_tr):\n",
    "    '''\n",
    "    1) Удаляет повторяющиеся строки\n",
    "    2) преобразует даты (по возможности)\n",
    "    3) делает отчет по датафрейму\n",
    "    '''\n",
    "    \n",
    "    duplicates_mask = df_tr.duplicated()\n",
    "    df_tr = df_tr[~duplicates_mask]\n",
    "    L = []\n",
    "    print('Дубликаты: % дубликатов строк = {:.1%}\\n'.format(duplicates_mask.mean()))\n",
    "    for col in df_tr.columns[:-1]:\n",
    "        try:\n",
    "            df_tr[col] = df_tr[col].astype('datetime64')\n",
    "        except:\n",
    "            pass\n",
    "        ser = df_tr[col]\n",
    "        _dtype = ser.dtype\n",
    "        _nuniques = ser.nunique()\n",
    "        if _dtype not in  ('object', 'datetime64[ns]'):\n",
    "            mn, mx = ser.min(), ser.max()\n",
    "        else:\n",
    "            mn, mx = np.nan, np.nan\n",
    "        L.append((col, _dtype, _nuniques, ser.isna().mean().round(2), mn, mx))\n",
    "        \n",
    "    report_df = pd.DataFrame.from_records(L)\\\n",
    "                  .rename(columns = {0:'признак', 1:'тип', 2:'число_уник_зн',\\\n",
    "                                     3:'доля nan', 4:'миниум', 5:'максимум'})\n",
    "    print('Таблица:')\n",
    "    print(report_df)\n",
    "    \n",
    "    return df_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
