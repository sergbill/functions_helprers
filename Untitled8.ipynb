{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# базовые библиотеки\n",
    "from sklearn.model_selection import cross_validate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.sparse import hstack, vstack, csc_matrix\n",
    "import os, re, sys, gc, pickle, time\n",
    "from collections import defaultdict\n",
    "import joblib\n",
    "\n",
    "# валидация, оптимизация гиперпараметров\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score,\\\n",
    "                                    KFold, train_test_split, cross_validate, ParameterGrid\n",
    "from sklearn.base import BaseEstimator, TransformerMixin,  clone\n",
    "# пайплайн\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin,  clone\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler, OneHotEncoder\n",
    "\n",
    "# дамми-регрессор\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import time\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import shutil\n",
    "\n",
    "# нейронные сети \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# вспомогательные модули\n",
    "from bil_ml_tools import SklearnHelperMulticollinearityReducer, SklearnHelperRegressorValidator,\\\n",
    "                         SklearnHelperMetaFeaturesRegressor,\\\n",
    "                         SklearnHelperFeatureSelector, SklearnHelperTargetEncoder,\\\n",
    "                         SklearnHelperColumnSelector, SklearnHelperLabelEncoder,\\\n",
    "                         train_hold_test_split, convert_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# константы\n",
    "SEED = 13\n",
    "FILL_NA = -9999\n",
    "# валидация\n",
    "KF = KFold(3, random_state = SEED, shuffle = True)\n",
    "# метрика качества\n",
    "def NEG_RMSE_SCORING_FUNC(y_true, y_pred):\n",
    "    return -np.sqrt(np.mean((y_true-y_pred)**2))\n",
    "NEG_RMSE_SCORER = make_scorer(NEG_RMSE_SCORING_FUNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_dtypes(pd.read_csv('datasets/autos.csv'))\n",
    "df_c = df.copy()\n",
    "# добавляем признаки\n",
    "for col in ['DateCrawled', 'LastSeen']:\n",
    "    df_c[col+'.year'] = df[col].dt.year\n",
    "    df_c[col+'.month'] =df[col].dt.month\n",
    "    df_c[col+'.day'] =df[col].dt.day\n",
    "    df_c[col+'.dayofweek'] =df[col].dt.dayofweek\n",
    "    df_c[col+'.hour'] = df[col].dt.hour    \n",
    "    df_c[col+'.minute'] = df[col].dt.minute    \n",
    "    df_c[col+'.weekofyear'] =df[col].dt.weekofyear\n",
    "    df_c[col+'.quarter'] =df[col].dt.quarter    \n",
    "df_c['DateCreated.year'] = df['DateCreated'].dt.year\n",
    "df_c['DateCreated.month'] = df['DateCreated'].dt.month\n",
    "df_c['DateCreated.day'] = df['DateCreated'].dt.day\n",
    "df_c = df_c.drop(['DateCreated', 'DateCrawled', 'LastSeen'], 1)\n",
    "\n",
    "del df\n",
    "gc.collect()\n",
    "df_c = df_c.loc[:, df_c.nunique()!=1]\n",
    "FEATURES, TARGET = df_c.drop('Price', 1), df_c['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tr, features_ho, features_te, target_tr, target_ho, target_te = \\\n",
    "    train_hold_test_split(FEATURES, TARGET,\n",
    "                          tr_size=.9,\\\n",
    "                          ho_size=.1,\\\n",
    "                          shuffle=True,\\\n",
    "                          random_state=SEED,\\\n",
    "                          stratify=False,\\\n",
    "                          use_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_lin_tr.pkl', 'rb') as f:\n",
    "    X_lin_tr = pickle.load(f)    \n",
    "with open('X_lin_ho.pkl', 'rb') as f:\n",
    "    X_lin_ho = pickle.load(f)    \n",
    "with open('X_lin_te.pkl', 'rb') as f:\n",
    "    X_lin_te = pickle.load(f)\n",
    "\n",
    "with open('X_tree_tr.pkl', 'rb') as f:\n",
    "    X_tree_tr = pickle.load(f)    \n",
    "with open('X_tree_ho.pkl', 'rb') as f:\n",
    "    X_tree_ho = pickle.load(f)    \n",
    "with open('X_tree_te.pkl', 'rb') as f:\n",
    "    X_tree_te = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr, y_ho, y_te = target_tr.values,target_ho.values, target_te.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnHelperRegressorHPTuner(BaseEstimator, TransformerMixin):    \n",
    "    def __init__(self, model, cv, scoring):\n",
    "        self.model = model\n",
    "        self.cv = cv\n",
    "        self.scoring = scoring\n",
    "    def info(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        assert (isinstance(X, np.ndarray)) or (X.getformat() == 'csc')\n",
    "        best_estimator_ = clone(self.model)\n",
    "        best_params = {}\n",
    "        if type(self.model).__name__ == 'LGBMRegressor':     \n",
    "            init_params = self.model.get_params()\n",
    "            bp = {'n_estimators':init_params['n_estimators'],\\\n",
    "                  'random_state':init_params['random_state'],\\\n",
    "                  'n_jobs':init_params['n_jobs']}\n",
    "            \n",
    "            gs = GridSearchCV(best_estimator_,\\\n",
    "                              param_grid = {'n_estimators':[10], 'n_jobs':[-1], 'random_state':[SEED],\\\n",
    "                                            'max_depth':np.arange(4, 21).tolist(),\\\n",
    "                                            'num_leaves':[32, 64, 128, 256, 512, 1024],\\\n",
    "                                            'min_child_samples':[20, 50]},\\\n",
    "                              cv = self.cv,\\\n",
    "                              scoring=self.scoring,\\\n",
    "                              n_jobs=-1, verbose=1)\n",
    "            gs.fit(X, y)\n",
    "            best_params.update(gs.best_params_)\n",
    "            best_estimator_ = best_estimator_.set_params(**best_params)\n",
    "            \n",
    "            gs = GridSearchCV(best_estimator_,\\\n",
    "                              param_grid = {'subsample':np.linspace(.1, 1, 10),\\\n",
    "                                            'colsample_bytree':np.linspace(.1, 1, 10)},\\\n",
    "                              cv = self.cv,\\\n",
    "                              scoring=self.scoring,\\\n",
    "                              n_jobs=-1, verbose=1)\n",
    "            gs.fit(X, y)\n",
    "            best_params.update(gs.best_params_)\n",
    "            best_params['n_estimators'] = bp['n_estimators']\n",
    "            best_params['random_state'] = bp['random_state']\n",
    "            best_params['n_jobs'] = bp['n_jobs']\n",
    "            best_estimator_ = best_estimator_.set_params(**best_params)\n",
    "            \n",
    "            learning_rates = [.005,.006, .007, .008, .009,\\\n",
    "                              .01, .02, .03, .04, .05, .06, .07, .08, .09,\\\n",
    "                              .1, .2, .3, .4, .5]\n",
    "            best_score = -np.inf\n",
    "            for lr in tqdm_notebook(learning_rates):\n",
    "                best_params['learning_rate'] = lr\n",
    "                lgb_curr = best_estimator_.set_params(**best_params)\n",
    "                mean_cv_score = cross_val_score(lgb_curr, X, y, cv = self.cv, scoring = self.scoring).mean()\n",
    "                if mean_cv_score>best_score:\n",
    "                    best_score = mean_cv_score\n",
    "                    best_lr = lr\n",
    "                else:\n",
    "                    break\n",
    "            best_score = -np.inf\n",
    "            for lr in tqdm_notebook(np.linspace(best_lr-.009,best_lr+.009, 50)):\n",
    "                best_params['learning_rate'] = lr\n",
    "                lgb_curr = best_estimator_.set_params(**best_params)\n",
    "                mean_cv_score = cross_val_score(lgb_curr, X, y, cv = self.cv, scoring = self.scoring).mean()\n",
    "                if mean_cv_score>best_score:\n",
    "                    best_score = mean_cv_score\n",
    "                    self.best_estimator_ = lgb_curr\n",
    "                else:\n",
    "                    break\n",
    "            self.best_score_ =  best_score                   \n",
    "        elif type(self.model).__name__ == 'XGBRegressor': \n",
    "            init_params = self.model.get_params()\n",
    "            bp = {'n_estimators':init_params['n_estimators'],\\\n",
    "                  'random_state':init_params['random_state'],\\\n",
    "                  'n_jobs':init_params['n_jobs']}\n",
    "            \n",
    "            gs = GridSearchCV(best_estimator_,\\\n",
    "                              param_grid = {'n_estimators':[10], 'n_jobs':[-1], 'random_state':[SEED],\\\n",
    "                                            'max_depth':np.arange(4, 21).tolist(),\\\n",
    "                                            'min_child_weight':[20, 50]},\\\n",
    "                              cv = self.cv,\\\n",
    "                              scoring=self.scoring,\\\n",
    "                              n_jobs=-1, verbose=1)\n",
    "            gs.fit(X, y)\n",
    "            best_params.update(gs.best_params_)\n",
    "            best_estimator_ = best_estimator_.set_params(**best_params)\n",
    "            \n",
    "            gs = GridSearchCV(best_estimator_,\\\n",
    "                              param_grid = {'subsample':[.5, .6, .7, .8, .9, 1],\\\n",
    "                                            'colsample_bytree':[.5, .6, .7, .8, .9, 1]},\\\n",
    "                              cv = self.cv,\\\n",
    "                              scoring=self.scoring,\\\n",
    "                              n_jobs=-1, verbose=1)\n",
    "            gs.fit(X, y)\n",
    "            best_params.update(gs.best_params_)\n",
    "            best_params['n_estimators'] = bp['n_estimators']\n",
    "            best_params['random_state'] = bp['random_state']\n",
    "            best_params['n_jobs'] = bp['n_jobs']\n",
    "            best_estimator_ = best_estimator_.set_params(**best_params)\n",
    "            \n",
    "            learning_rates = [.005,.006, .007, .008, .009,\\\n",
    "                              .01, .02, .03, .04, .05, .06, .07, .08, .09,\\\n",
    "                              .1, .2, .3, .4, .5]\n",
    "            best_score = -np.inf\n",
    "            for lr in tqdm_notebook(learning_rates):\n",
    "                best_params['learning_rate'] = lr\n",
    "                xgb_curr = best_estimator_.set_params(**best_params)\n",
    "                mean_cv_score = cross_val_score(xgb_curr, X, y, cv = self.cv, scoring = self.scoring).mean()\n",
    "                if mean_cv_score>best_score:\n",
    "                    best_score = mean_cv_score\n",
    "                    best_lr = lr\n",
    "                else:\n",
    "                    break\n",
    "            best_score = -np.inf\n",
    "            for lr in tqdm_notebook(np.linspace(best_lr-.009,best_lr+.009, 50)):\n",
    "                best_params['learning_rate'] = lr\n",
    "                xgb_curr = best_estimator_.set_params(**best_params)\n",
    "                mean_cv_score = cross_val_score(xgb_curr, X, y, cv = self.cv, scoring = self.scoring).mean()\n",
    "                if mean_cv_score>best_score:\n",
    "                    best_score = mean_cv_score\n",
    "                    self.best_estimator_ = xgb_curr\n",
    "                else:\n",
    "                    break\n",
    "            self.best_score_ = best_score                    \n",
    "        elif type(self.model).__name__ in ('DecisionTreeRegressor', 'ExtraTreeRegressor'):\n",
    "            gs = GridSearchCV(best_estimator_,\\\n",
    "                              param_grid = {'max_depth':np.arange(7, 41), 'min_samples_leaf':[2, 20, 200]},\\\n",
    "                              cv = self.cv,\\\n",
    "                              scoring=self.scoring,\\\n",
    "                              n_jobs=-1, verbose=1)\n",
    "            gs.fit(X, y)\n",
    "            best_params.update(gs.best_params_)\n",
    "            self.best_estimator_ = best_estimator_.set_params(**best_params)\n",
    "            self.best_score_ = gs.best_score_\n",
    "        elif type(self.model).__name__ in ('RandomForestRegressor', 'ExtraTreesRegressor'):\n",
    "            init_params = self.model.get_params()\n",
    "            bp = {'n_estimators':init_params['n_estimators'],\\\n",
    "                  'random_state':init_params['random_state'],\\\n",
    "                  'n_jobs':init_params['n_jobs']}\n",
    "            gs = GridSearchCV(best_estimator_,\\\n",
    "                              param_grid = {'max_depth':np.arange(5, 21),'min_samples_leaf':[2, 20],\\\n",
    "                                            'n_estimators':[10], 'n_jobs':[-1], 'random_state':[bp['random_state']]},\\\n",
    "                              cv = self.cv,\\\n",
    "                              scoring=self.scoring,\\\n",
    "                              n_jobs=-1, verbose=1)\n",
    "            gs.fit(X, y)\n",
    "            best_params.update(gs.best_params_)\n",
    "            best_params['n_estimators'] = bp['n_estimators']\n",
    "            best_params['random_state'] = bp['random_state']\n",
    "            best_params['n_jobs'] = bp['n_jobs']\n",
    "            self.best_estimator_ = best_estimator_.set_params(**best_params)\n",
    "            self.best_score_ = cross_val_score(self.best_estimator_,\\\n",
    "                                               X, y,\\\n",
    "                                               cv = self.cv, scoring=self.scoring, n_jobs=-1).mean()\n",
    "        elif type(self.model).__name__ in ('Ridge', 'Lasso'):            \n",
    "            gs = GridSearchCV(best_estimator_,\\\n",
    "                              param_grid = {'alpha':[.001, .002, .003, .004, .005,\\\n",
    "                                                     .01, .02, .03, .04, .05, .06, .07, .08, .09,\\\n",
    "                                                     .1, .2, .3, .4, .5, .6, .7, .8, .9,\\\n",
    "                                                     1, 2, 3, 4, 5],\\\n",
    "                                           'normalize':[True]},\\\n",
    "                              cv = self.cv,\\\n",
    "                              scoring=self.scoring,\\\n",
    "                              n_jobs=-1, verbose=1)\n",
    "            gs.fit(X, y)\n",
    "            self.best_estimator_ = gs.best_estimator_\n",
    "            self.best_score_ = gs.best_score_\n",
    "            \n",
    "        elif type(self.model).__name__ == 'LinearSVR':\n",
    "            gs = GridSearchCV(best_estimator_,\\\n",
    "                              param_grid = {'C':[.5, 1, 2, 4, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100,\\\n",
    "                                                 150, 200, 250, 300, 350, 400, 450, 500]},\\\n",
    "                              cv = self.cv,\\\n",
    "                              scoring=self.scoring,\\\n",
    "                              n_jobs=-1, verbose=1)\n",
    "            gs.fit(X, y)\n",
    "            self.best_estimator_ = gs.best_estimator_\n",
    "            self.best_score_ = gs.best_score_\n",
    "            \n",
    "        elif type(self.model).__name__ == 'KNeighborsRegressor':\n",
    "            gs = GridSearchCV(best_estimator_,\\\n",
    "                              param_grid = {'n_neighbors':range(2, 11)},\\\n",
    "                              cv = self.cv,\\\n",
    "                              scoring=self.scoring,\\\n",
    "                              n_jobs=-1, verbose=1)\n",
    "            gs.fit(X, y)\n",
    "            self.best_estimator_ = gs.best_estimator_\n",
    "            self.best_score_ = gs.best_score_\n",
    "            \n",
    "        self.best_estimator_.fit(X, y) \n",
    "        try:\n",
    "            self.coef_imp = self.best_estimator_.coef_.flatten()\n",
    "        except:\n",
    "            self.coef_imp = self.best_estimator_.feture_importances_.flatten()        \n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return self.best_estimator_.predict(X)      \n",
    "    \n",
    "class SklearnHelperFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    ''' Отбор признаков '''\n",
    "    def __init__(self, model, cv, scoring, show_progress):\n",
    "        self.model = model\n",
    "        self.cv = cv\n",
    "        self.scoring = scoring\n",
    "        self.show_progress = show_progress\n",
    "    def fit(self, X, y=None):\n",
    "        assert (isinstance(X, np.ndarray)) or (X.getformat() == 'csc')\n",
    "        cv_scores = []\n",
    "        for i in tqdm_notebook(range(_X.shape[1])):\n",
    "            try:\n",
    "                _X_curr = _X[:, i].toarray().reshape(-1,1)\n",
    "            except:\n",
    "                _X_curr = _X[:, i].reshape(-1,1)                \n",
    "            mean_cv_score = cross_val_score(self.model, _X_curr, y, cv =self.cv, scoring = self.scoring, n_jobs=-1).mean()            \n",
    "            cv_scores.append(mean_cv_score)\n",
    "            \n",
    "        order = np.argsort(cv_scores)[::-1]\n",
    "        to_drop_before, best_features, best_cv_score = [], [order[0]], -np.inf\n",
    "        for i in tqdm_notebook(order[1:]):\n",
    "            curr_features = best_features+[i]\n",
    "            _X_curr = _X[:, curr_features]\n",
    "            mean_cv_score = cross_val_score(self.model, _X_curr, y, cv =self.cv, scoring = self.scoring, n_jobs=-1).mean()\n",
    "            if mean_cv_score>best_cv_score:\n",
    "                best_cv_score = mean_cv_score\n",
    "                best_features = curr_features\n",
    "                if self.show_progress:\n",
    "                    print('new best score = {:.5f}'.format(best_cv_score))\n",
    "            else:\n",
    "                to_drop_before.append(i)\n",
    "        while True:\n",
    "            to_drop_after = []\n",
    "            for i in tqdm_notebook(to_drop_before):\n",
    "                curr_features = best_features+[i]\n",
    "                _X_curr = _X[:, curr_features]\n",
    "                mean_cv_score = cross_val_score(self.model, _X_curr, y, cv =self.cv, scoring = self.scoring, n_jobs=-1).mean()\n",
    "                if mean_cv_score>best_cv_score:\n",
    "                    best_cv_score = mean_cv_score\n",
    "                    best_features = curr_features\n",
    "                    if self.show_progress:\n",
    "                        print('new best score = {:.5f}'.format(best_cv_score))\n",
    "                else:\n",
    "                    to_drop_after.append(i)\n",
    "            if to_drop_before == to_drop_after:\n",
    "                break\n",
    "            else:\n",
    "                to_drop_before = to_drop_after  \n",
    "        self.best_features = best_features\n",
    "        self.best_cv_score = best_cv_score\n",
    "    def transform(self, X):\n",
    "        return _X[:, self.best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_tuner = SklearnHelperRegressorHPTuner(model = Ridge(random_state= SEED),\\\n",
    "                                            cv = KF,\\\n",
    "                                            scoring = NEG_RMSE_SCORER)\n",
    "linearsvr_tuner = SklearnHelperRegressorHPTuner(model = LinearSVR(),\\\n",
    "                                            cv = KF,\\\n",
    "                                            scoring = NEG_RMSE_SCORER)\n",
    "knn_tuner = SklearnHelperRegressorHPTuner(model = KNeighborsRegressor(),\\\n",
    "                                            cv = KF,\\\n",
    "                                            scoring = NEG_RMSE_SCORER)\n",
    "dt_tuner = SklearnHelperRegressorHPTuner(model = DecisionTreeRegressor(),\\\n",
    "                                            cv = KF,\\\n",
    "                                            scoring = NEG_RMSE_SCORER)\n",
    "et_tuner = SklearnHelperRegressorHPTuner(model = ExtraTreeRegressor(),\\\n",
    "                                            cv = KF,\\\n",
    "                                            scoring = NEG_RMSE_SCORER)\n",
    "rf_tuner = SklearnHelperRegressorHPTuner(model = RandomForestRegressor(),\\\n",
    "                                            cv = KF,\\\n",
    "                                            scoring = NEG_RMSE_SCORER)\n",
    "ets_tuner = SklearnHelperRegressorHPTuner(model = ExtraTreesRegressor(),\\\n",
    "                                            cv = KF,\\\n",
    "                                            scoring = NEG_RMSE_SCORER)\n",
    "lgb_tuner = SklearnHelperRegressorHPTuner(model = LGBMRegressor(n_jobs=-1, random_state= SEED),\\\n",
    "                                        cv = KF,\\\n",
    "                                        scoring = NEG_RMSE_SCORER)\n",
    "xgb_tuner = SklearnHelperRegressorHPTuner(model = XGBRegressor(n_jobs=-1, random_state= SEED),\\\n",
    "                                        cv = KF,\\\n",
    "                                        scoring = NEG_RMSE_SCORER)\n",
    "\n",
    "# наименования моделей\n",
    "L_best_estimators_names = ['Ridge','LinearSVR','KNeighborsRegressor','DecisionTree',\\\n",
    "                           'ExtraTree','RandomForest','ExtraTrees','Lightgbm','XGBoost']\n",
    "\n",
    "# оптмизаторы гиперпараметров\n",
    "L_hptuners = [ridge_tuner, linearsvr_tuner, knn_tuner, dt_tuner, et_tuner, rf_tuner, ets_tuner, lgb_tuner, xgb_tuner]\n",
    "\n",
    "# признаки\n",
    "L_base_X_tr = (X_lin_tr, X_lin_tr, X_tree_tr, X_tree_tr, X_tree_tr, X_tree_tr, X_tree_tr, X_tree_tr, X_tree_tr)\n",
    "L_base_X_ho = (X_lin_ho, X_lin_ho, X_tree_ho, X_tree_ho, X_tree_ho, X_tree_ho, X_tree_ho, X_tree_ho, X_tree_ho)\n",
    "L_base_X_te = (X_lin_te, X_lin_te, X_tree_te, X_tree_te, X_tree_te, X_tree_te, X_tree_te, X_tree_te, X_tree_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc926d786794b4caa3216b172995a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed:   14.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 23 candidates, totalling 69 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of  69 | elapsed:   36.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 102 candidates, totalling 306 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 306 out of 306 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 102 candidates, totalling 306 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   59.6s\n",
      "[Parallel(n_jobs=-1)]: Done 306 out of 306 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 204 candidates, totalling 612 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 612 out of 612 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667b4ee670ff4cf899c93e60aec55c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e707f0af5d43efbe7c7b62a6d88010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 3 folds for each of 34 candidates, totalling 102 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done 102 out of 102 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbe3eda89fd491eb301fff3df68f8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=19.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed09737c4f9b43eda54a963e57bb5c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "D_tuners = {}\n",
    "L_cvAB = []\n",
    "for name, tuner, X_tr, X_ho in tqdm_notebook(zip(L_best_estimators_names, L_hptuners, L_base_X_tr, L_base_X_ho),\\\n",
    "                                             total = len(L_best_estimators_names)):\n",
    "    \n",
    "    start = time.time()\n",
    "    tuner.fit(X_tr, y_tr)  \n",
    "    end = time.time()\n",
    "    duration = round(end - start)\n",
    "    \n",
    "    D_tuners[name] = tuner\n",
    "    \n",
    "    mean_cv_score = tuner.best_score_\n",
    "    ho_score = NEG_RMSE_SCORING_FUNC(y_ho, tuner.predict(X_ho))\n",
    "    \n",
    "    L_cvAB.append((name, mean_cv_score, ho_score, duration))\n",
    "    \n",
    "cvAB = pd.DataFrame(L_cvAB, columns = ['model', 'cv', 'ho', 'duration']).set_index('model').abs().sort_values('ho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_values = [[1658.3696729058192, 1651.033588994316, 1840.0],\n",
    " [1659.3959979856463, 1652.6949683713735, 552.0],\n",
    " [1696.7469431322731, 1686.8034695407114, 529.0],\n",
    " [1731.746899524733, 1711.96235265943, 694.0],\n",
    " [1987.450608882015, 1968.9164993050645, 160.0],\n",
    " [2036.5300070397982, 2020.1216114481401, 105.0],\n",
    " [2104.8194806322613, 2131.1950747669393, 16.0],\n",
    " [2175.164966299662, 2200.292824822986, 52.0]]\n",
    "L_columns = ['cv', 'ho', 'duration']\n",
    "L_index = ['XGBoost', 'Lightgbm', 'ExtraTrees', 'RandomForest', 'DecisionTree',\n",
    "       'ExtraTree', 'Ridge', 'LinearSVR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvAB = pd.DataFrame(L_values, columns = L_columns, index = L_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv</th>\n",
       "      <th>ho</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>1658.369673</td>\n",
       "      <td>1651.033589</td>\n",
       "      <td>1840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm</th>\n",
       "      <td>1659.395998</td>\n",
       "      <td>1652.694968</td>\n",
       "      <td>552.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees</th>\n",
       "      <td>1696.746943</td>\n",
       "      <td>1686.803470</td>\n",
       "      <td>529.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>1731.746900</td>\n",
       "      <td>1711.962353</td>\n",
       "      <td>694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>1987.450609</td>\n",
       "      <td>1968.916499</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTree</th>\n",
       "      <td>2036.530007</td>\n",
       "      <td>2020.121611</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>2104.819481</td>\n",
       "      <td>2131.195075</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>2175.164966</td>\n",
       "      <td>2200.292825</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cv           ho  duration\n",
       "XGBoost       1658.369673  1651.033589    1840.0\n",
       "Lightgbm      1659.395998  1652.694968     552.0\n",
       "ExtraTrees    1696.746943  1686.803470     529.0\n",
       "RandomForest  1731.746900  1711.962353     694.0\n",
       "DecisionTree  1987.450609  1968.916499     160.0\n",
       "ExtraTree     2036.530007  2020.121611     105.0\n",
       "Ridge         2104.819481  2131.195075      16.0\n",
       "LinearSVR     2175.164966  2200.292825      52.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnHelperStackingRegressor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, L_base_models, n_iterations, nfolds, seed, path_to_folder):\n",
    "        self.L_base_models = L_base_models        \n",
    "        self.n_iterations = n_iterations\n",
    "        self.nfolds = nfolds\n",
    "        self.seed = seed\n",
    "        self.path_to_folder=path_to_folder\n",
    "        \n",
    "        if os.path.isdir(self.path_to_folder):\n",
    "            shutil.rmtree(self.path_to_folder)\n",
    "            os.makedirs(self.path_to_folder)\n",
    "        else:\n",
    "            os.makedirs(self.path_to_folder) \n",
    "            \n",
    "    def fit(self, L_X, y=None):\n",
    "        L_Z = []\n",
    "        self.nrows = L_X[0].shape[0]\n",
    "        print('classic stacking ...')\n",
    "        # классический стекинг\n",
    "        for i, (model, X) in tqdm_notebook(enumerate(zip(self.L_base_models, L_X)),\\\n",
    "                                              total = len(self.L_base_models)):\n",
    "            current_seed=i+self.seed\n",
    "            kf = KFold(self.nfolds, random_state= current_seed, shuffle = True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # пустые таблицы\n",
    "            Z_tr = np.zeros((y.shape[0], 1))            \n",
    "\n",
    "            # запускаем фолдинг\n",
    "            for j, (tr_idx, val_idx) in tqdm_notebook(enumerate(kf.split(X, y)),\\\n",
    "                                                      total = self.nfolds):\n",
    "                model.fit(X[tr_idx], y[tr_idx])\n",
    "                \n",
    "                filename = os.path.join(self.path_to_folder, f'model_{i+1}_{j+1}.pickle')\n",
    "                with open(filename, 'wb') as f:\n",
    "                    pickle.dump((model, None, i, j), f)\n",
    "                    \n",
    "                Z_tr[val_idx, 0] = model.predict(X[val_idx])                \n",
    "\n",
    "            L_Z.append(Z_tr)\n",
    "            \n",
    "        self.Z = np.column_stack(L_Z)\n",
    "        if self.n_iterations is not None:\n",
    "            print('random model + features + oversampling stacking ...')\n",
    "            indexes = np.arange(len(self.L_base_models))\n",
    "            subsamples = [.5, .6, .7, .8, .9]\n",
    "            L_Z = []\n",
    "            # повторяем n_iterations раз\n",
    "            for i in tqdm_notebook(range(self.n_iterations)):\n",
    "                current_seed=i+self.seed\n",
    "                # фиксируем сид\n",
    "                np.random.RandomState(current_seed)\n",
    "\n",
    "                # выбираем индекс\n",
    "                current_idx = np.random.choice(indexes)\n",
    "                # выбираем долю признаков, которые будут участвовать в обучении\n",
    "                subsample = np.random.choice(subsamples)\n",
    "                # фиксируем валидацию\n",
    "                kf = KFold(self.nfolds, random_state= current_seed, shuffle = True)\n",
    "\n",
    "                # получаем модель, признаки\n",
    "                current_model = self.L_base_models[current_idx]\n",
    "                _x_tr = L_X[current_idx]\n",
    "\n",
    "\n",
    "                # размеры признаков\n",
    "                nrows, ncols = _x_tr.shape\n",
    "\n",
    "                # выбираем признаки, которые будут участвовать в обучении\n",
    "                columns_to_use = np.random.choice(np.arange(ncols),\\\n",
    "                                               np.int32(np.around(ncols*subsample)),\\\n",
    "                                               replace = False)\n",
    "                # получаем подпространства признаков\n",
    "                _x_subset_tr = _x_tr[:, columns_to_use]\n",
    "\n",
    "                del _x_tr\n",
    "                gc.collect()\n",
    "\n",
    "                # пустые таблицы\n",
    "                Z = np.zeros((y.shape[0], 1))            \n",
    "\n",
    "                # запускаем фолдинг\n",
    "                for j, (tr_idx, val_idx) in tqdm_notebook(enumerate(kf.split(_x_subset_tr, y)),\\\n",
    "                                                          total = self.nfolds):\n",
    "\n",
    "                    # тренировочная, валидационна выборки\n",
    "                    _x_train = _x_subset_tr[tr_idx] \n",
    "                    _x_valid = _x_subset_tr[val_idx] \n",
    "\n",
    "                    # выбор строк из тренировочного датасета с возвращением\n",
    "                    rows_to_use = np.random.choice(np.arange(_x_train.shape[0]), nrows, replace = True)\n",
    "\n",
    "                    # обучаем модель\n",
    "                    current_model.fit(_x_train[rows_to_use], y_tr[rows_to_use])\n",
    "\n",
    "                    filename = os.path.join(self.path_to_folder, f'model2_{i+1}_{j+1}.pickle')\n",
    "                    with open(filename, 'wb') as f:\n",
    "                        pickle.dump((current_model, columns_to_use, i, j), f)\n",
    "\n",
    "                    # получаем метапризнаки\n",
    "                    Z[val_idx, 0] = current_model.predict(_x_valid)\n",
    "\n",
    "\n",
    "                # коллекционируем\n",
    "                L_Z.append(Z)\n",
    "\n",
    "            self.Z2 = np.column_stack(L_Z)        \n",
    "            self.Z_final = np.column_stack([self.Z, self.Z2])\n",
    "            self.Z = self.Z_final\n",
    "            del self.Z_final\n",
    "            gc.collect()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, L_X):\n",
    "        if self.nrows == L_X[0].shape[0]:\n",
    "            return self.Z     \n",
    "        else:            \n",
    "            L = []\n",
    "            for file in tqdm_notebook(os.listdir(self.path_to_folder)):    \n",
    "                with open(os.path.join(self.path_to_folder, file), 'rb') as f:\n",
    "                    model, columns_to_use, i, j =pickle.load(f)\n",
    "                if columns_to_use is None:\n",
    "                    L.append(model.predict(L_X[i]))\n",
    "                else:\n",
    "                    L.append(model.predict(L_X[i][:, columns_to_use]))\n",
    "                    \n",
    "            XX = np.column_stack(L)\n",
    "            if self.n_iterations is not None:\n",
    "                X_meta = np.column_stack([arr.mean(1) for arr in np.array_split(XX,\\\n",
    "                                                                                self.n_iterations*self.nfolds, axis = 1)])\n",
    "            else:\n",
    "                X_meta = np.column_stack([arr.mean(1) for arr in np.array_split(XX,self.nfolds, axis = 1)])\n",
    "                \n",
    "            \n",
    "            return X_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_base_models = [Ridge(), LinearSVR()]\n",
    "L_base_X_tr = (X_lin_tr, X_lin_tr)\n",
    "L_base_X_ho = (X_lin_ho, X_lin_ho)\n",
    "L_base_X_te = (X_lin_te, X_lin_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_reg = SklearnHelperStackingRegressor(L_base_models = L_base_models,\\\n",
    "                                              n_iterations=2,\n",
    "                                              nfolds=5,\\\n",
    "                                              seed=SEED,\\\n",
    "                                              path_to_folder = r'C:\\Users\\Sergey\\anaconda3\\Scripts\\stacking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classic stacking ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616ccdd61d124828aacf7acb5b6ea91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac2beb837b547d493bcb8362c928d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b06a7aa76947dfb006e730d63cc40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "random model + features + oversampling stacking ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d432cc208f47c2a72a0d633cb38a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e992f404b05f4db3bd4780cf20a3c011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5aad828f9f24fa5850cd929c2fb46d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stacking_reg.fit(L_base_X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_reg.predict(L_base_X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_reg.predict(L_base_X_ho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_reg.predict(L_base_X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
